{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "546e2cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\amush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     C:\\Users\\amush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\amush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import importlib\n",
    "import wic\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cdist\n",
    "importlib.reload(wic)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4884b49e",
   "metadata": {},
   "source": [
    "# Gloss Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eea027ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('kanishka/GlossBERT')\n",
    "model = BertForSequenceClassification.from_pretrained('kanishka/GlossBERT')\n",
    "model.to(device)\n",
    "\n",
    "# Custom Dataset to handle sentence pairs with labels\n",
    "# Custom Dataset\n",
    "class SentencePairDataset(Dataset):\n",
    "    def __init__(self, sentence_pairs_with_labels):\n",
    "        self.data = sentence_pairs_with_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Collate function\n",
    "def collate_fn_glossb(batch):\n",
    "    sentences1 = [item[0] for item in batch]\n",
    "    sentences2 = [item[1] for item in batch]\n",
    "    labels = torch.tensor([item[2] for item in batch], dtype=torch.long)\n",
    "    inputs = tokenizer(sentences1, sentences2, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    return inputs, labels, batch\n",
    "\n",
    "# Evaluation Function\n",
    "def classify_and_evaluate(dataloader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, raw_batch in dataloader:\n",
    "            # Move inputs and labels to device\n",
    "            inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            predicted_labels = torch.argmax(probs, dim=-1)\n",
    "\n",
    "            # Accuracy\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted_labels == labels).sum().item()\n",
    "\n",
    "            # Store results\n",
    "            for i in range(len(raw_batch)):\n",
    "                sentence1, sentence2, gold_label = raw_batch[i]\n",
    "                pred_label = predicted_labels[i].item()\n",
    "                confidence = probs[i][1].item()\n",
    "                results.append({\n",
    "                    'sentence1': sentence1,\n",
    "                    'sentence2': sentence2,\n",
    "                    'gold_label': gold_label,\n",
    "                    'predicted_label': pred_label,\n",
    "                    'confidence': confidence\n",
    "                })\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return results, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71460107",
   "metadata": {},
   "source": [
    "# Custom Fined Tuned Model (Triplet Loss Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef925b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSDTripletDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, tokenizer, max_length):\n",
    "        self.dataset = hf_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset.iloc[idx]  # Use iloc for pandas DataFrame\n",
    "\n",
    "        def tokenize(text):\n",
    "            tokens = self.tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            return {\n",
    "                'input_ids': tokens['input_ids'].squeeze(0),\n",
    "                'attention_mask': tokens['attention_mask'].squeeze(0)\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            'anchor': tokenize(data['anchor']),\n",
    "            'positive': tokenize(data['positive']),\n",
    "            'negative': tokenize(data['negative']),\n",
    "            'target_word': data['target_word']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a2b0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletBERT(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(TripletBERT, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        self.fc = nn.Linear(self.hidden_size, 256)\n",
    "\n",
    "    def get_embedding(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        proj = self.fc(cls_output)\n",
    "        return proj  \n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        anchor_embed = self.get_embedding(anchor[\"input_ids\"], anchor[\"attention_mask\"])\n",
    "        positive_embed = self.get_embedding(positive[\"input_ids\"], positive[\"attention_mask\"])\n",
    "        negative_embed = self.get_embedding(negative[\"input_ids\"], negative[\"attention_mask\"])\n",
    "        return anchor_embed, positive_embed, negative_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c37bb",
   "metadata": {},
   "source": [
    "## TinyBert Fine-Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8df6b111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amush\\AppData\\Local\\Temp\\ipykernel_4408\\104132968.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_tiny.load_state_dict(torch.load(r\"C:\\Users\\amush\\INLP_Project\\Finetuning\\triplet_fine_tuned_tinybert.pth\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "tokenizer_tiny = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Reinitialize model and load state_dict\n",
    "model_tiny = TripletBERT(model_name=model_name).to(device)\n",
    "model_tiny.load_state_dict(torch.load(r\"C:\\Users\\amush\\INLP_Project\\Finetuning\\triplet_fine_tuned_tinybert.pth\", map_location=device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c0896",
   "metadata": {},
   "source": [
    "## DistilBert Fine-Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "142c7273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amush\\AppData\\Local\\Temp\\ipykernel_4408\\2375615602.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_distil.load_state_dict(torch.load(r\"C:\\Users\\amush\\INLP_Project\\Finetuning\\triplet_fine_tuned_distil.pth\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer_distil = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Reinitialize model and load state_dict\n",
    "model_distil = TripletBERT(model_name=model_name).to(device)\n",
    "model_distil.load_state_dict(torch.load(r\"C:\\Users\\amush\\INLP_Project\\Finetuning\\triplet_fine_tuned_distil.pth\", map_location=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd9bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3317f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1a743b",
   "metadata": {},
   "source": [
    "# SemEval 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9d22df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This document is a summary of the European Pub...</td>\n",
       "      <td>This document is a summary of the European Pub...</td>\n",
       "      <td>document</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It explains how the Committee for Medicinal Pr...</td>\n",
       "      <td>It explains how the Committee for Medicinal Pr...</td>\n",
       "      <td>explain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you want more information on the basis of t...</td>\n",
       "      <td>If we want to understand how it works , the be...</td>\n",
       "      <td>want</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you want more information on the basis of t...</td>\n",
       "      <td>If you want to use a typical f(x) function it ...</td>\n",
       "      <td>want</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If we want to understand how it works , the be...</td>\n",
       "      <td>If you want to use a typical f(x) function it ...</td>\n",
       "      <td>want</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sent1  \\\n",
       "0  This document is a summary of the European Pub...   \n",
       "1  It explains how the Committee for Medicinal Pr...   \n",
       "2  If you want more information on the basis of t...   \n",
       "3  If you want more information on the basis of t...   \n",
       "4  If we want to understand how it works , the be...   \n",
       "\n",
       "                                               sent2     lemma  ground_truth  \n",
       "0  This document is a summary of the European Pub...  document             0  \n",
       "1  It explains how the Committee for Medicinal Pr...   explain             0  \n",
       "2  If we want to understand how it works , the be...      want             0  \n",
       "3  If you want to use a typical f(x) function it ...      want             0  \n",
       "4  If you want to use a typical f(x) function it ...      want             0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem15 = pd.read_csv(r'C:\\Users\\amush\\INLP_Project\\Finetuning\\semeval2015.csv')\n",
    "sem15.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14faf3a0",
   "metadata": {},
   "source": [
    "### TinyBert Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "735f6cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6822429906542056\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "cosin_dis = 0\n",
    "dist = 0\n",
    "model_tiny.eval()\n",
    "\n",
    "for i in range(len(sem15)):\n",
    "    \n",
    "    sentence1 = sem15['sent1'][i]\n",
    "    sentence2 = sem15['sent2'][i]\n",
    "    \n",
    "    sentence1_tokens = tokenizer_tiny(sentence1, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    sentence2_tokens = tokenizer_tiny(sentence2, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")  \n",
    "    \n",
    "    sentence1_tokens = {k: v.to(device) for k, v in sentence1_tokens.items()}\n",
    "    sentence2_tokens = {k: v.to(device) for k, v in sentence2_tokens.items()} \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embedding1 = model_tiny.get_embedding(sentence1_tokens['input_ids'], sentence1_tokens['attention_mask'])\n",
    "        embedding2 = model_tiny.get_embedding(sentence2_tokens['input_ids'], sentence2_tokens['attention_mask'])\n",
    "        \n",
    "        \n",
    "    embedding1 = embedding1.cpu().numpy()\n",
    "    embedding2 = embedding2.cpu().numpy()   \n",
    "    \n",
    "    cosine_sim = cosine_similarity(embedding1, embedding2)\n",
    "    \n",
    "    embedding1 = embedding1 / np.linalg.norm(embedding1, axis=1, keepdims=True)\n",
    "    embedding2 = embedding2 / np.linalg.norm(embedding2, axis=1, keepdims=True)\n",
    "\n",
    "    dis = cdist(embedding1, embedding2, metric = 'euclidean')\n",
    "    \n",
    "    label = 0\n",
    "    \n",
    "    if dis < 0.01:\n",
    "        label = 1\n",
    "    \n",
    "    correct += (label == sem15['ground_truth'][i])\n",
    "    \n",
    "print(correct/len(sem15))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b75c883",
   "metadata": {},
   "source": [
    "### DistilBert Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9a58a1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7476635514018691\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "cosin_dis = 0\n",
    "dist = 0\n",
    "model_distil.eval()\n",
    "\n",
    "for i in range(len(sem15)):\n",
    "    \n",
    "    sentence1 = sem15['sent1'][i]\n",
    "    sentence2 = sem15['sent2'][i]\n",
    "    \n",
    "    sentence1_tokens = tokenizer_distil(sentence1, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    sentence2_tokens = tokenizer_distil(sentence2, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")  \n",
    "    \n",
    "    sentence1_tokens = {k: v.to(device) for k, v in sentence1_tokens.items()}\n",
    "    sentence2_tokens = {k: v.to(device) for k, v in sentence2_tokens.items()} \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embedding1 = model_distil.get_embedding(sentence1_tokens['input_ids'], sentence1_tokens['attention_mask'])\n",
    "        embedding2 = model_distil.get_embedding(sentence2_tokens['input_ids'], sentence2_tokens['attention_mask'])\n",
    "        \n",
    "        \n",
    "    embedding1 = embedding1.cpu().numpy()\n",
    "    embedding2 = embedding2.cpu().numpy()   \n",
    "    \n",
    "    cosine_sim = cosine_similarity(embedding1, embedding2)\n",
    "    \n",
    "    embedding1 = embedding1 / np.linalg.norm(embedding1, axis=1, keepdims=True)\n",
    "    embedding2 = embedding2 / np.linalg.norm(embedding2, axis=1, keepdims=True)\n",
    "\n",
    "    dis = cdist(embedding1, embedding2, metric = 'euclidean')\n",
    "    \n",
    "    label = 0\n",
    "    \n",
    "    if dis < 0.4:\n",
    "        label = 1\n",
    "    \n",
    "    correct += (label == sem15['ground_truth'][i])\n",
    "    \n",
    "print(correct/len(sem15))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2776c6e2",
   "metadata": {},
   "source": [
    "### GlossBert Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc77176e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5794392523364486"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glossbert_data = [(sem15['sent1'][i], sem15['sent2'][i], sem15['ground_truth'][i]) for i in range(len(sem15))]\n",
    "dataset = SentencePairDataset(glossbert_data)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False, collate_fn=collate_fn_glossb)\n",
    "model.to(device)\n",
    "# Run classification and compute accuracy\n",
    "results, accuracy = classify_and_evaluate(dataloader)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c303c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309d45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0f24f6e",
   "metadata": {},
   "source": [
    "# SemEval 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "50e8508a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The U.N.-sponsored climate conference -- chara...</td>\n",
       "      <td>Artur Runge-Metzger , who heads international ...</td>\n",
       "      <td>climate</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It gives a lot of flexibility to the process ,...</td>\n",
       "      <td>There is a lot of consensus between the Left a...</td>\n",
       "      <td>lot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Together , the countries would cut emissions b...</td>\n",
       "      <td>Some of the countries most vulnerable to the i...</td>\n",
       "      <td>country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U.S. special climate envoy Todd Stern rejected...</td>\n",
       "      <td>U.S. firms were in some cases at a disadvantag...</td>\n",
       "      <td>u.s.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S. special climate envoy Todd Stern rejected...</td>\n",
       "      <td>Major U.S. firms such as Chevron and ConocoPhi...</td>\n",
       "      <td>u.s.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sent1  \\\n",
       "0  The U.N.-sponsored climate conference -- chara...   \n",
       "1  It gives a lot of flexibility to the process ,...   \n",
       "2  Together , the countries would cut emissions b...   \n",
       "3  U.S. special climate envoy Todd Stern rejected...   \n",
       "4  U.S. special climate envoy Todd Stern rejected...   \n",
       "\n",
       "                                               sent2    lemma  ground_truth  \n",
       "0  Artur Runge-Metzger , who heads international ...  climate             0  \n",
       "1  There is a lot of consensus between the Left a...      lot             0  \n",
       "2  Some of the countries most vulnerable to the i...  country             0  \n",
       "3  U.S. firms were in some cases at a disadvantag...     u.s.             0  \n",
       "4  Major U.S. firms such as Chevron and ConocoPhi...     u.s.             0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem13 = pd.read_csv(r'C:\\Users\\amush\\INLP_Project\\Finetuning\\semeval2013.csv')\n",
    "sem13.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fb7371",
   "metadata": {},
   "source": [
    "### TinyBert Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eee853cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7466666666666667\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "cosin_dis = 0\n",
    "dist = 0\n",
    "model_tiny.eval()\n",
    "\n",
    "for i in range(len(sem13)):\n",
    "    \n",
    "    sentence1 = sem13['sent1'][i]\n",
    "    sentence2 = sem13['sent2'][i]\n",
    "    \n",
    "    sentence1_tokens = tokenizer_tiny(sentence1, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    sentence2_tokens = tokenizer_tiny(sentence2, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")  \n",
    "    \n",
    "    sentence1_tokens = {k: v.to(device) for k, v in sentence1_tokens.items()}\n",
    "    sentence2_tokens = {k: v.to(device) for k, v in sentence2_tokens.items()} \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embedding1 = model_tiny.get_embedding(sentence1_tokens['input_ids'], sentence1_tokens['attention_mask'])\n",
    "        embedding2 = model_tiny.get_embedding(sentence2_tokens['input_ids'], sentence2_tokens['attention_mask'])\n",
    "        \n",
    "        \n",
    "    embedding1 = embedding1.cpu().numpy()\n",
    "    embedding2 = embedding2.cpu().numpy()   \n",
    "    \n",
    "    cosine_sim = cosine_similarity(embedding1, embedding2)\n",
    "    \n",
    "    embedding1 = embedding1 / np.linalg.norm(embedding1, axis=1, keepdims=True)\n",
    "    embedding2 = embedding2 / np.linalg.norm(embedding2, axis=1, keepdims=True)\n",
    "\n",
    "    dis = cdist(embedding1, embedding2, metric = 'euclidean')\n",
    "    \n",
    "    label = 0\n",
    "    \n",
    "    if dis < 0.01:\n",
    "        label = 1\n",
    "    \n",
    "    correct += (label == sem13['ground_truth'][i])\n",
    "    \n",
    "print(correct/len(sem13))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e71fb",
   "metadata": {},
   "source": [
    "### DistilBert Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "603c7cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7733333333333333\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "cosin_dis = 0\n",
    "dist = 0\n",
    "model_distil.eval()\n",
    "\n",
    "for i in range(len(sem13)):\n",
    "    \n",
    "    sentence1 = sem13['sent1'][i]\n",
    "    sentence2 = sem13['sent2'][i]\n",
    "    \n",
    "    sentence1_tokens = tokenizer_distil(sentence1, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    sentence2_tokens = tokenizer_distil(sentence2, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")  \n",
    "    \n",
    "    sentence1_tokens = {k: v.to(device) for k, v in sentence1_tokens.items()}\n",
    "    sentence2_tokens = {k: v.to(device) for k, v in sentence2_tokens.items()} \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embedding1 = model_distil.get_embedding(sentence1_tokens['input_ids'], sentence1_tokens['attention_mask'])\n",
    "        embedding2 = model_distil.get_embedding(sentence2_tokens['input_ids'], sentence2_tokens['attention_mask'])\n",
    "        \n",
    "        \n",
    "    embedding1 = embedding1.cpu().numpy()\n",
    "    embedding2 = embedding2.cpu().numpy()   \n",
    "    \n",
    "    cosine_sim = cosine_similarity(embedding1, embedding2)\n",
    "    \n",
    "    embedding1 = embedding1 / np.linalg.norm(embedding1, axis=1, keepdims=True)\n",
    "    embedding2 = embedding2 / np.linalg.norm(embedding2, axis=1, keepdims=True)\n",
    "\n",
    "    dis = cdist(embedding1, embedding2, metric = 'euclidean')\n",
    "    \n",
    "    label = 0\n",
    "    \n",
    "    if dis < 0.4:\n",
    "        label = 1\n",
    "    \n",
    "    correct += (label == sem13['ground_truth'][i])\n",
    "    \n",
    "print(correct/len(sem13))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "426a3a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5533333333333333"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glossbert_data = [(sem13['sent1'][i], sem13['sent2'][i], sem13['ground_truth'][i]) for i in range(len(sem13))]\n",
    "dataset = SentencePairDataset(glossbert_data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False, collate_fn=collate_fn_glossb)\n",
    "model.to(device)\n",
    "# Run classification and compute accuracy\n",
    "results, accuracy = classify_and_evaluate(dataloader)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c21a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c23049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c1326c7",
   "metadata": {},
   "source": [
    "# RAW-C (Related Words in Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6662bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>act</td>\n",
       "      <td>It was a desperate act.</td>\n",
       "      <td>It was a magic act.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act</td>\n",
       "      <td>It was a desperate act.</td>\n",
       "      <td>It was a comedic act.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>act</td>\n",
       "      <td>It was a humane act.</td>\n",
       "      <td>It was a magic act.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>act</td>\n",
       "      <td>It was a humane act.</td>\n",
       "      <td>It was a comedic act.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>act</td>\n",
       "      <td>It was a desperate act.</td>\n",
       "      <td>It was a humane act.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>yard</td>\n",
       "      <td>It was five yards.</td>\n",
       "      <td>They were cluttered yards.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>yard</td>\n",
       "      <td>It was ten yards.</td>\n",
       "      <td>They were big yards.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>yard</td>\n",
       "      <td>It was ten yards.</td>\n",
       "      <td>They were cluttered yards.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>yard</td>\n",
       "      <td>It was five yards.</td>\n",
       "      <td>It was ten yards.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>yard</td>\n",
       "      <td>They were big yards.</td>\n",
       "      <td>They were cluttered yards.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    lemma                    sent1                       sent2  ground_truth\n",
       "0     act  It was a desperate act.         It was a magic act.             0\n",
       "1     act  It was a desperate act.       It was a comedic act.             0\n",
       "2     act     It was a humane act.         It was a magic act.             0\n",
       "3     act     It was a humane act.       It was a comedic act.             0\n",
       "4     act  It was a desperate act.        It was a humane act.             1\n",
       "..    ...                      ...                         ...           ...\n",
       "667  yard       It was five yards.  They were cluttered yards.             0\n",
       "668  yard        It was ten yards.        They were big yards.             0\n",
       "669  yard        It was ten yards.  They were cluttered yards.             0\n",
       "670  yard       It was five yards.           It was ten yards.             1\n",
       "671  yard     They were big yards.  They were cluttered yards.             1\n",
       "\n",
       "[672 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawc = pd.read_csv(r'C:\\Users\\amush\\INLP_Project\\Finetuning\\raw-c.csv')\n",
    "rawc = rawc[['word', 'sentence1', 'sentence2', 'same']]\n",
    "rawc = rawc.rename(columns={'word':'lemma', 'sentence1': 'sent1', 'sentence2': 'sent2', 'same':'ground_truth'})\n",
    "rawc['ground_truth']  = rawc['ground_truth'].apply(lambda x : 0 if x == False else 1)\n",
    "rawc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d57ecb",
   "metadata": {},
   "source": [
    "### TinyBert Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3089946b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6279761904761905\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "cosin_dis = 0\n",
    "dist = 0\n",
    "model_tiny.eval()\n",
    "\n",
    "for i in range(len(rawc)):\n",
    "    \n",
    "    sentence1 = rawc['sent1'][i]\n",
    "    sentence2 = rawc['sent2'][i]\n",
    "    \n",
    "    sentence1_tokens = tokenizer_tiny(sentence1, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    sentence2_tokens = tokenizer_tiny(sentence2, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")  \n",
    "    \n",
    "    sentence1_tokens = {k: v.to(device) for k, v in sentence1_tokens.items()}\n",
    "    sentence2_tokens = {k: v.to(device) for k, v in sentence2_tokens.items()} \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embedding1 = model_tiny.get_embedding(sentence1_tokens['input_ids'], sentence1_tokens['attention_mask'])\n",
    "        embedding2 = model_tiny.get_embedding(sentence2_tokens['input_ids'], sentence2_tokens['attention_mask'])\n",
    "        \n",
    "        \n",
    "    embedding1 = embedding1.cpu().numpy()\n",
    "    embedding2 = embedding2.cpu().numpy()   \n",
    "    \n",
    "    cosine_sim = cosine_similarity(embedding1, embedding2)\n",
    "    \n",
    "    embedding1 = embedding1 / np.linalg.norm(embedding1, axis=1, keepdims=True)\n",
    "    embedding2 = embedding2 / np.linalg.norm(embedding2, axis=1, keepdims=True)\n",
    "\n",
    "    dis = cdist(embedding1, embedding2, metric = 'euclidean')\n",
    "    \n",
    "    label = 0\n",
    "    \n",
    "    if dis < 0.01:\n",
    "        label = 1\n",
    "    \n",
    "    correct += (label == rawc['ground_truth'][i])\n",
    "    \n",
    "print(correct/len(rawc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfdfb82",
   "metadata": {},
   "source": [
    "### DistilBert Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a3616ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6934523809523809\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "cosin_dis = 0\n",
    "dist = 0\n",
    "model_distil.eval()\n",
    "\n",
    "for i in range(len(rawc)):\n",
    "    \n",
    "    sentence1 = rawc['sent1'][i]\n",
    "    sentence2 = rawc['sent2'][i]\n",
    "    \n",
    "    sentence1_tokens = tokenizer_distil(sentence1, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    sentence2_tokens = tokenizer_distil(sentence2, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")  \n",
    "    \n",
    "    sentence1_tokens = {k: v.to(device) for k, v in sentence1_tokens.items()}\n",
    "    sentence2_tokens = {k: v.to(device) for k, v in sentence2_tokens.items()} \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embedding1 = model_distil.get_embedding(sentence1_tokens['input_ids'], sentence1_tokens['attention_mask'])\n",
    "        embedding2 = model_distil.get_embedding(sentence2_tokens['input_ids'], sentence2_tokens['attention_mask'])\n",
    "        \n",
    "        \n",
    "    embedding1 = embedding1.cpu().numpy()\n",
    "    embedding2 = embedding2.cpu().numpy()   \n",
    "    \n",
    "    cosine_sim = cosine_similarity(embedding1, embedding2)\n",
    "    \n",
    "    embedding1 = embedding1 / np.linalg.norm(embedding1, axis=1, keepdims=True)\n",
    "    embedding2 = embedding2 / np.linalg.norm(embedding2, axis=1, keepdims=True)\n",
    "\n",
    "    dis = cdist(embedding1, embedding2, metric = 'euclidean')\n",
    "    \n",
    "    label = 0\n",
    "    \n",
    "    if dis < 0.4:\n",
    "        label = 1\n",
    "    \n",
    "    correct += (label == rawc['ground_truth'][i])\n",
    "    \n",
    "print(correct/len(rawc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4634c279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6190476190476191"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glossbert_data = [(rawc['sent1'][i], rawc['sent2'][i], rawc['ground_truth'][i]) for i in range(len(rawc))]\n",
    "dataset = SentencePairDataset(glossbert_data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False, collate_fn=collate_fn_glossb)\n",
    "model.to(device)\n",
    "# Run classification and compute accuracy\n",
    "results, accuracy = classify_and_evaluate(dataloader)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e474be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
